{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSC413 Project",
      "provenance": [],
      "authorship_tag": "ABX9TyOvQjt92H9mJs8pwxg/fYC1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/st-tran/CSC413-Project/blob/main/CSC413_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zqBfjJaSb1f"
      },
      "source": [
        "# CSC413 Project: GeoGuessr!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9_vebVc9pe2"
      },
      "source": [
        "## A bunch of imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2BGwVTO9kyj"
      },
      "source": [
        "from typing import *\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from glob import glob\n",
        "import re\n",
        "import os\n",
        "from random import shuffle\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkpoovwQF8px"
      },
      "source": [
        "## Visualizing stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRjsKGuBF-yS"
      },
      "source": [
        "def visualize_example(tup):\n",
        "  dst = Image.new(\"RGB\", (1024, 256))\n",
        "  dst.paste(tup[0][0], (0, 0))\n",
        "  dst.paste(tup[0][1], (256, 0))\n",
        "  dst.paste(tup[0][2], (512, 0))\n",
        "  dst.paste(tup[0][3], (768, 0))\n",
        "  display(dst)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5TO3a4w9ij-"
      },
      "source": [
        "## Load in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmbfEpE7NpSc"
      },
      "source": [
        "# 1k Canada dataset\n",
        "!gdown --id 1QSVxo_GpPQ5gHVh6hkQCEktt6jGX3AoO\n",
        "!mkdir /content/training\n",
        "!tar -xzvf 1kimages090180270.tar.gz -C /content/training\n",
        "!for d in /content/training/images*; do mv \"${d}\" \"/content/training/`basename \"${d}\" | sed -e 's/images//g' | sed -e 's/\\s//g'`\"; done\n",
        "!rm -rf /content/1kimages090180270.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OkYE4BCSbBq"
      },
      "source": [
        "data = defaultdict(list)\n",
        "\n",
        "def get_image_ids(province: str) -> List[str]:\n",
        "  images = glob(f\"/content/training/{province}/*.jpg\")\n",
        "  ids_no_angle = [re.sub('_[\\\\d]*.jpg', '', f) for f in images]\n",
        "  return ids_no_angle \n",
        "\n",
        "def stitch_images_and_save(image_base_path: str) -> None:\n",
        "  img = Image.new(\"RGB\", (512, 512))\n",
        "  img_0 = Image.open(f\"{image_base_path}_0.jpg\")\n",
        "  img_90 = Image.open(f\"{image_base_path}_90.jpg\")\n",
        "  img_180 = Image.open(f\"{image_base_path}_180.jpg\")\n",
        "  img_270 = Image.open(f\"{image_base_path}_270.jpg\")\n",
        "  img.paste(img_0, (0, 0))\n",
        "  img.paste(img_90, (256, 0))\n",
        "  img.paste(img_180, (0, 256))\n",
        "  img.paste(img_270, (256, 256))\n",
        "\n",
        "  new_name = f\"{image_base_path}_stitched.jpg\"\n",
        "  img.save(new_name)\n",
        "  data[image_base_path.split(\"/\")[-2]].append(new_name)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqhBUFsi--uW"
      },
      "source": [
        "## A custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AkFRDNp_BPG"
      },
      "source": [
        "class GeoDataset(Dataset):\n",
        "  \"\"\"\n",
        "  Holds a bunch of (N, E, S, W) quadruplets of examples along with the corresponding province labels.\n",
        "\n",
        "  # Todo: maybe add transform?\n",
        "  \"\"\"\n",
        "  def __init__(self, index_file, transform=None, shuf=False):\n",
        "    self.index_file = index_file\n",
        "    self.transform = transform\n",
        "\n",
        "    self.labels = index_files.keys()\n",
        "\n",
        "    # Data has (N, E, S, W, province)\n",
        "    self.data = []\n",
        "    for prov, tups in index_file.items():\n",
        "      for tup in tups:\n",
        "        self.data.append((*tup, prov))\n",
        "    if shuf:\n",
        "      shuffle(self.data)\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \"\"\"\n",
        "    Returns: \n",
        "      (N, E, S, W) images, province\n",
        "    tuple\n",
        "    \"\"\"\n",
        "    tup = self.data[idx]\n",
        "    return tuple(\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "          (ToTensor()(Image.open(t))) for t in tup[:-1]\n",
        "        ), tup[-1]\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOPP93kRUM2l"
      },
      "source": [
        "index_files = defaultdict(list)\n",
        "\n",
        "for province in glob(\"/content/training/*\"):\n",
        "  name = os.path.basename(province)\n",
        "  for image in get_image_ids(name):\n",
        "    # stitch_images_and_save(image)\n",
        "    index_files[name].append(tuple(f\"{image}_{angle}.jpg\" for angle in (\"0\", \"90\", \"180\", \"270\")))"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18pMalbyAXIq"
      },
      "source": [
        "dataset = GeoDataset(index_files, shuf=True)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIXpqjIvJjzK"
      },
      "source": [
        "images, labels = next(iter(loader))"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG75j1AjTAQu"
      },
      "source": [
        "## Code to actually do the training logic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUN3VLvgS_49"
      },
      "source": [
        "class AttrDict(dict):\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    super(AttrDict, self).__init__(*args, **kwargs)\n",
        "    self.__dict__ = self\n",
        "\n",
        "\n",
        "def compute_loss(criterion, outputs, labels, batch_size, num_colours):\n",
        "  \"\"\" Copied from A2 \"\"\"\n",
        "  loss_out = outputs.transpose(1, 3).contiguous().view([-1, num_colors])\n",
        "  loss_lab = labels.transpose(1, 3).contiguous().view([-1])\n",
        "  return criterion(loss_out, loss_lab)\n",
        "\n",
        "def train(args, cnn=None):\n",
        "  save_dir = f\"/outputs/{args.experiment_name}\"\n",
        "  num_labels = len(dataset.labels)\n",
        "  num_in_channels = 3\n",
        "\n",
        "  if cnn is None:\n",
        "    Net = globals()[args.model]\n",
        "    cnn = Net(args.kernel, args.num_filters, num_colours, num_in_channels)\n",
        "\n",
        "  # Loss function\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(cnn.parameters(), lr=args.learn_rate)\n",
        "\n",
        "  print(\"Beginning training...\")\n",
        "  if args.gpu:\n",
        "    cnn.cuda()\n",
        "  start = time.time()\n",
        "\n",
        "  train_losses = []\n",
        "  valid_losses = []\n",
        "  valid_accs = []\n",
        "  for epoch in range(args.epochs):\n",
        "    # Train the model\n",
        "    cnn.train()\n",
        "    losses = []\n",
        "    for i, (images, labels) in enumerate(dataset):\n",
        "      # Forward + Backward + Optimize\n",
        "      optimizer.zero_grad()\n",
        "      outputs = cnn(images)\n",
        "\n",
        "      loss = compute_loss(\n",
        "          criterion, outputs, labels, batch_size=args.batch_size, num_colours=num_colours\n",
        "      )\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      losses.append(loss.data.item())\n",
        "\n",
        "      # plot training images\n",
        "      avg_loss = np.mean(losses)\n",
        "      train_losses.append(avg_loss)\n",
        "      time_elapsed = time.time() - start\n",
        "      print(\n",
        "          \"Epoch [%d/%d], Loss: %.4f, Time (s): %d\"\n",
        "          % (epoch + 1, args.epochs, avg_loss, time_elapsed)\n",
        "      )\n",
        "\n",
        "      # Evaluate the model\n",
        "      cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
        "      val_loss, val_acc = run_validation_step(\n",
        "          cnn,\n",
        "          criterion,\n",
        "          test_grey,\n",
        "          test_rgb_cat,\n",
        "          args.batch_size,\n",
        "          colours,\n",
        "          save_dir + \"/test_%d.png\" % epoch,\n",
        "          args.visualize,\n",
        "          args.downsize_input,\n",
        "      )\n",
        "\n",
        "      time_elapsed = time.time() - start\n",
        "      valid_losses.append(val_loss)\n",
        "      valid_accs.append(val_acc)\n",
        "      print(\n",
        "          \"Epoch [%d/%d], Val Loss: %.4f, Val Acc: %.1f%%, Time(s): %.2f\"\n",
        "          % (epoch + 1, args.epochs, val_loss, val_acc, time_elapsed)\n",
        "      )\n",
        "\n",
        "  # Plot training curve\n",
        "  plt.figure()\n",
        "  plt.plot(train_losses, \"ro-\", label=\"Train\")\n",
        "  plt.plot(valid_losses, \"go-\", label=\"Validation\")\n",
        "  plt.legend()\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.savefig(save_dir + \"/training_curve.png\")\n",
        "\n",
        "  if args.checkpoint:\n",
        "      print(\"Saving model...\")\n",
        "      torch.save(cnn.state_dict(), args.checkpoint)\n",
        "\n",
        "  return cnn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SahPklYDWlBh"
      },
      "source": [
        "## 18-Layer Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFhzjZHVWoqN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}